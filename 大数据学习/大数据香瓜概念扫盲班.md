# 大数据香瓜概念扫盲 🤪

## 零碎概念

### Cloud ☁️

> 分布式存储与计算

### BI

商业智能（Business Intelligence，简称：BI），又称商业智慧或商务智能，指用现代数据仓库技术、线上分析处理技术、数据挖掘和数据展现技术进行数据分析以实现商业价值

参考：[数据观察家 Matt Turck 和他的 BLOG](https://mattturck.com/data2019/#more-1221)

### Kerberos

**Kerberos**是一种计算机网络授权协议，用来在非安全网络中，对个人通信以安全的手段进行身份认证，

KDC（Key Distribution Center）密钥分发中心

### Apache Hadoop

> *Hadoop* 是一个由Apache基金会所开发的分布式系统基础架构

Hadoop 生态圈基本上都是为了处理超过单机尺度的数据处理而诞生的

Hadoop 项目下包含了很多子项目，从计算到存储都有，比如HDFS、MapReduce、YARN、HBase。

参考：[如何用形象的比喻描述大数据的技术生态？Hadoop、Hive、Spark 之间是什么关系？](https://www.zhihu.com/question/27974418/answer/38965760)

大致概念：底层HDFS【数据】，上面跑 MapReduce / Tez / Spark【计算引擎】，再上面跑 Hive / Pig【计算工具】

## OLTP服务

> On-line Transaction Processing：联机事务处理

OLTP是传统的关系型数据库的主要应用，主要是基本的、日常的事务处理，例如银行交易。其特点是会有高并发且数据量级不大的查询，是主要用于管理事务（transaction-oriented)的系统。涉及的数据量比较少，例如查询name=“dag” 只需对某几行数据进行操作

广义理解🤔：对外 快速

***常见的技术：MySQL Hbase  Redis HDFS***

### Apache Hadoop HBase ：

HBase 是一个分布式列式存储系统，同样属于 Hadoop 的子项目 【列式存储】

### HDFS：*存储海量数据的方案！*

HDFS 全称叫做 Hadoop 分布式文件系统，其主要由一个 NameNode(NN) 和多个 DataNode(DN) 组成，数据文件会分成多个 Block，这些Block按照不同主机，不同机架的策略以默认一备三的情况分布存储在各个节点

HDFS 的设计本质上是为了大量的数据能横跨成百上千台机器，但是用户看到的只是一个文件系统而不是很多文件系统



## OLAP服务

> On-line Analytical Processing：联机分析处理

OLAP是数据仓库系统的主要应用，支持复杂的分析操作，侧重决策支持，并且提供直观易懂的查询结果。其特点是查询频率较OLTP系统更低，但通常会涉及到非常复杂的聚合计算。涉及的数据量较大，例如求平均值需对多行数据进行操作 

广义理解🤔：对内 慢速

***常见的技术：MapReduce Hive Spark Doris Kudu ClickHouse Kylin***

### MapReduce：*第一代计算引擎！*

MapReduce 的设计采用了很简化的计算模型，只有 Map 和 Reduce 两个计算过程（中间用 Shuffle 串联），用这个模型已经可以处理大数据领域很大一部分问题了。

当我们用很多台机器处理数据，就会面临了如何分配工作，如果一台机器挂了如何重新启动相应的任务，机器之间如何互相通信交换数据以完成复杂的计算等等。这就是 MapReduce、Tez、Spark 的功能，MapReduce 是第一代计算引擎，Tez 和 Spark 是第二代。

### Apache Hadoop Kudu

Kudu 是一个和 HBase 非常类似的产品，其不同之处在于 Kudu 不依赖 Zookeeper 来管理自己的集群，并且 HBase 的数据是保存在 HDFS 上的，而 Kudu 拥有自己的数据文件格式

### [Apache Hive & Tez](https://hive.apache.org/)

>  Hive 是用 SQL的方式去描述 MapReduce程序！Tez 是对 Hive 的优化

（ MapReduce 的程序写起来很麻烦，`Pig` 是用接近脚本方式去描述 MapReduce，Hive 则用的是 SQL 去描述 MapReduce，它们把脚本和SQL语言翻译成 MapReduce 程序，丢给计算引擎去计算，而用户就可以从繁琐的 MapReduce 程序中解脱出来，用更简单更直观的语言去写程序了）

Hive 是 ***最有名气的*** 数据仓库工具，他将 HDFS 上的数据组织成关系型数据库的形式，并提供了 HiveSQL 进行结构化查询，使得数据分析人员可以从传统的关系型数据库几乎无缝的过渡到 HDFS 上，但其个别函数和传统 SQL 还是有区别的，并且默认也不支持 update 和 delete 操作。

Hive 本身的计算是基于 MapReduce 的，后来为了应对 SparkSQL 的出现，开发组推出了Hive on Spark，使得 SQL 的解释、分析、优化还是在 Hive 上，而执行阶段交由 Spark 去完成，从而以达到和 SparkSQL 近似的速度。

Tez 是对 Hive 的另一项优化，为其引入了 DAG 的概念，增加任务并行度从而提升 Hive 的查询速度，但其本质仍旧是 MapReduce，所以提升效果相比 Hive on Spark 来讲并不足够明显

### [Apache Spark](https://spark.apache.org/)  

>  Hive on Tez / Spark，极速版的MR引擎！

Spark 是由加州大学伯克利分校推出的分布式计算引擎，在 Spark 的官方主页上有一张和 Hadoop 的性能对比图，姑且不谈这张图中数据的准确性，但是 Spark 的确将 Hadoop（主要是指 MapReduce ）的性能提升了一个量级。

得益于两个方面：第一个是 Spark 计算过程中生成的中间数据不再落盘，没有了 Spill 的阶段。第二个是引入 DAG 对任务进行拆解，一个完整的 Job 被分成多个 Stage，每个 Stage 里面又有多个 Task，通过一张有向无环图，使得没有依赖关系的Task可以并行运行。

Spark 虽好，但其对内存资源消耗也很大，同时也使得他在稳定性上不如 MapReduce，所以有些大公司数仓的日常任务仍旧采用传统 MapReduce 的方式执行，不求最快，但求最稳。