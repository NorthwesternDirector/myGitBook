### 大数据香瓜概念扫盲

#### BI

商业智能（Business Intelligence，简称：BI），又称商业智慧或商务智能，指用现代数据仓库技术、线上分析处理技术、数据挖掘和数据展现技术进行数据分析以实现商业价值

参考：[数据观察家 Matt Turck 和他的 BLOG](https://mattturck.com/data2019/#more-1221)

#### Kerberos

**Kerberos**是一种计算机网络授权协议，用来在非安全网络中，对个人通信以安全的手段进行身份认证，

KDC（Key Distribution Center）密钥分发中心



***2019年人工智能和大数据产业图***👇



#### Apache Hadoop

Hadoop生态圈基本上都是为了处理超过单机尺度的数据处理而诞生的

Hadoop 项目下包含了很多子项目，从计算到存储都有，比如HDFS、MapReduce、YARN、HBase。

参考：[如何用形象的比喻描述大数据的技术生态？Hadoop、Hive、Spark 之间是什么关系？](https://www.zhihu.com/question/27974418/answer/38965760)

大致概念：底层HDFS【数据】，上面跑 MapReduce / Tez / Spark【计算引擎】，再上面跑 Hive / Pig【计算工具】

##### HDFS：*存储海量数据的方案！*

HDFS 全称叫做 Hadoop 分布式文件系统，其主要由一个 NameNode(NN) 和多个 DataNode(DN) 组成，数据文件会分成多个 Block，这些Block按照不同主机，不同机架的策略以默认一备三的情况分布存储在各个节点

HDFS 的设计本质上是为了大量的数据能横跨成百上千台机器，但是用户看到的只是一个文件系统而不是很多文件系统

#####  Apache Hadoop HBase & Kudu：

HBase 是一个分布式列式存储系统，同样属于 Hadoop 的子项目 【列式存储】

Kudu 是一个和 HBase 非常类似的产品，其不同之处在于 Kudu 不依赖 Zookeeper 来管理自己的集群，并且 HBase 的数据是保存在 HDFS 上的，而 Kudu 拥有自己的数据文件格式

##### MapReduce：*第一代计算引擎！*

MapReduce 的设计采用了很简化的计算模型，只有 Map 和 Reduce 两个计算过程（中间用 Shuffle 串联），用这个模型已经可以处理大数据领域很大一部分问题了。

当我们用很多台机器处理数据，就会面临了如何分配工作，如果一台机器挂了如何重新启动相应的任务，机器之间如何互相通信交换数据以完成复杂的计算等等。这就是 MapReduce、Tez、Spark 的功能，MapReduce 是第一代计算引擎，Tez 和 Spark 是第二代。

##### [Apache Hive & Tez：](https://hive.apache.org/)*Hive 是用 SQL的方式去描述 MapReduce程序！Tez 是对 Hive 的优化*

（ MapReduce 的程序写起来很麻烦，`Pig` 是用接近脚本方式去描述 MapReduce，Hive 则用的是 SQL 去描述 MapReduce，它们把脚本和SQL语言翻译成 MapReduce 程序，丢给计算引擎去计算，而用户就可以从繁琐的 MapReduce 程序中解脱出来，用更简单更直观的语言去写程序了）

Hive 是 ***最有名气的*** 数据仓库工具，他将 HDFS 上的数据组织成关系型数据库的形式，并提供了 HiveSQL 进行结构化查询，使得数据分析人员可以从传统的关系型数据库几乎无缝的过渡到 HDFS 上，但其个别函数和传统 SQL 还是有区别的，并且默认也不支持 update 和 delete 操作。

Hive 本身的计算是基于 MapReduce 的，后来为了应对 SparkSQL 的出现，开发组推出了Hive on Spark，使得 SQL 的解释、分析、优化还是在 Hive 上，而执行阶段交由 Spark 去完成，从而以达到和 SparkSQL 近似的速度。

Tez 是对 Hive 的另一项优化，为其引入了 DAG 的概念，增加任务并行度从而提升 Hive 的查询速度，但其本质仍旧是 MapReduce，所以提升效果相比 Hive on Spark 来讲并不足够明显

##### [Apache Spark：](https://spark.apache.org/)  *Hive on Tez / Spark，极速版的MR引擎！*

Spark 是由加州大学伯克利分校推出的分布式计算引擎，在 Spark 的官方主页上有一张和 Hadoop 的性能对比图，姑且不谈这张图中数据的准确性，但是 Spark 的确将 Hadoop（主要是指 MapReduce ）的性能提升了一个量级。

得益于两个方面：第一个是 Spark 计算过程中生成的中间数据不再落盘，没有了 Spill 的阶段。第二个是引入 DAG 对任务进行拆解，一个完整的 Job 被分成多个 Stage，每个 Stage 里面又有多个 Task，通过一张有向无环图，使得没有依赖关系的Task可以并行运行。

Spark 虽好，但其对内存资源消耗也很大，同时也使得他在稳定性上不如 MapReduce，所以有些大公司数仓的日常任务仍旧采用传统 MapReduce 的方式执行，不求最快，但求最稳。